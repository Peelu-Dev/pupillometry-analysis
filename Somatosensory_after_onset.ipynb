{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d6b25-805a-441d-87aa-509d90505db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import pyplr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.signal import savgol_filter\n",
    "import scipy.io as sio\n",
    "import statistics as stats\n",
    "from scipy.interpolate import interp1d\n",
    "import glob\n",
    "\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "from pyplr import graphing, utils, preproc\n",
    "from pyplr.plr import PLR\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Only use negative trials (original Neutral list removed)\n",
    "Negative = [11,12,13,14,15,16,17,18,19,20,31,32,33,34,35,36,37,38,39,40,51,52,53,54,55,56,57,58,59,60]\n",
    "\n",
    "def get_condition_label(trial_duration, median_duration):\n",
    "    \"\"\"Get the label for trial condition based on duration median split\"\"\"\n",
    "    if trial_duration > median_duration:\n",
    "        return \"LongDurationVisual\"\n",
    "    else:\n",
    "        return \"ShortDurationVisual\"\n",
    "\n",
    "# List of participant data files - replace with actual paths\n",
    "participant_files = [\n",
    "    '001_sirisha_v.mat',\n",
    "    #'002_ram_v.mat',\n",
    "    #'003_deepak_v.mat',\n",
    "    '004_brijesh_v.mat',\n",
    "    '005_piyush_v.mat',\n",
    "    #'006_hariharan_v.mat',\n",
    "    '007_sapna_v.mat',\n",
    "    '008_maitreyee_v.mat',\n",
    "    '009_shubham_v.mat',\n",
    "    #'011_anisha_v.mat'\n",
    "]\n",
    "\n",
    "# Structures to store data across all participants\n",
    "all_participants_LongDurationVisual_trials = []\n",
    "all_participants_ShortDurationVisual_trials = []\n",
    "all_participants_LongDurationVisual_baselines = []\n",
    "all_participants_ShortDurationVisual_baselines = []\n",
    "all_participants_baseline_avg = []\n",
    "\n",
    "# To store all trial durations for median calculation\n",
    "all_trial_durations = []\n",
    "\n",
    "# First pass to collect all trial durations for median calculation\n",
    "print(\"First pass: Collecting trial durations for median calculation...\")\n",
    "for participant_file in participant_files:\n",
    "    try:\n",
    "        participant_id = participant_file.split('_')[0]  # Extract participant ID\n",
    "        \n",
    "        # Load the mat file data (with error handling)\n",
    "        try:\n",
    "            mat_data = sio.loadmat(participant_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {participant_file}: {e}\")\n",
    "            continue  # Skip to next participant if file can't be loaded\n",
    "        \n",
    "        # Only process negative trials\n",
    "        for trial_num in Negative:\n",
    "            trial_key = f'Trial{trial_num}'\n",
    "            if trial_key in mat_data:\n",
    "                trial_data = mat_data[trial_key]\n",
    "                \n",
    "                # Get behavioral codes\n",
    "                behavioral_codes = trial_data['BehavioralCodes'][0, 0]\n",
    "                code_times = behavioral_codes['CodeTimes'][0, 0].flatten()\n",
    "                code_numbers = behavioral_codes['CodeNumbers'][0, 0].flatten()\n",
    "                \n",
    "                # Find stimulus onset (code 3) and offset (code 4)\n",
    "                time_2 = code_times[code_numbers == 2]\n",
    "                time_3 = code_times[code_numbers == 3]\n",
    "                \n",
    "                if len(time_2) == 0 or len(time_3) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate trial duration (stimulus duration)\n",
    "                trial_duration = time_3[0] - time_2[0]\n",
    "                all_trial_durations.append(trial_duration)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing participant {participant_file} in first pass: {e}\")\n",
    "\n",
    "# Calculate median duration\n",
    "if len(all_trial_durations) > 0:\n",
    "    median_duration = np.median(all_trial_durations)\n",
    "    print(f\"Median trial duration: {median_duration} ms\")\n",
    "else:\n",
    "    print(\"No valid trial durations found!\")\n",
    "    median_duration = 0\n",
    "\n",
    "# Target length for resampling\n",
    "target_length = 500\n",
    "\n",
    "# For final averages across participants\n",
    "all_LongDurationVisual_resampled = []\n",
    "all_ShortDurationVisual_resampled = []\n",
    "\n",
    "# NEW: Create dictionaries to store participant-level statistics\n",
    "participant_stats = {}\n",
    "\n",
    "# Process each participant\n",
    "for participant_file in participant_files:\n",
    "    try:\n",
    "        print(f\"Processing participant file: {participant_file}\")\n",
    "        participant_id = participant_file.split('_')[0]  # Extract participant ID\n",
    "        \n",
    "        # Lists to store trial data by condition for this participant\n",
    "        LongDurationVisual_condition_trials = []\n",
    "        ShortDurationVisual_condition_trials = []\n",
    "        LongDurationVisual_condition_baselines = []\n",
    "        ShortDurationVisual_condition_baselines = []\n",
    "        baseline_avg_array = []\n",
    "        \n",
    "        # Store trial durations for this participant\n",
    "        participant_trial_durations = {}\n",
    "        \n",
    "        # Load the mat file data (with error handling)\n",
    "        try:\n",
    "            mat_data = sio.loadmat(participant_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {participant_file}: {e}\")\n",
    "            continue  # Skip to next participant if file can't be loaded\n",
    "        \n",
    "        # Only process negative trials\n",
    "        for trial_num in Negative:\n",
    "            trial_key = f'Trial{trial_num}'\n",
    "            if trial_key in mat_data:\n",
    "                trial_data = mat_data[trial_key]\n",
    "                \n",
    "                # Get behavioral codes\n",
    "                behavioral_codes = trial_data['BehavioralCodes'][0, 0]\n",
    "                code_times = behavioral_codes['CodeTimes'][0, 0].flatten()\n",
    "                code_numbers = behavioral_codes['CodeNumbers'][0, 0].flatten()\n",
    "                \n",
    "                # Find stimulus onset (code 3) and offset (code 4)\n",
    "                time_2 = code_times[code_numbers == 2]\n",
    "                time_3 = code_times[code_numbers == 3]\n",
    "                \n",
    "                if len(time_2) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate trial duration if possible\n",
    "                if len(time_3) > 0:\n",
    "                    trial_duration = time_3[0] - time_2[0]\n",
    "                    participant_trial_durations[trial_num] = trial_duration\n",
    "                else:\n",
    "                    # Skip trials without clear offset\n",
    "                    continue\n",
    "                \n",
    "                # Determine condition based on median split\n",
    "                condition_label = get_condition_label(trial_duration, median_duration)\n",
    "                 \n",
    "                # Get raw data\n",
    "                analog_data = trial_data['AnalogData'][0, 0]\n",
    "                lsl = analog_data['LSL'][0, 0]\n",
    "                lsl_data = lsl['LSL1'][0, 0]\n",
    "                \n",
    "                # Extract timestamps and diameter data\n",
    "                timestamps = lsl_data[:, 0]\n",
    "                diameter0 = lsl_data[:, 19].astype(float)\n",
    "                diameter1 = lsl_data[:, 20].astype(float)\n",
    "                average_diameter = (diameter0 + diameter1) / 2\n",
    "\n",
    "                # Use global confidence\n",
    "                confidence = lsl_data[:, 1]\n",
    "\n",
    "                # MODIFIED: Only include data from time_2 - 1000ms up to time_2\n",
    "                time_start = time_3[0] - 3000\n",
    "                time_end = time_3[0]\n",
    "                mask = (timestamps >= time_start) & (timestamps <= time_end)\n",
    "                \n",
    "                # Get masked timestamps and data\n",
    "                masked_timestamps = timestamps[mask]\n",
    "                masked_confidence = confidence[mask]\n",
    "                masked_average_diameter = average_diameter[mask]\n",
    "\n",
    "                # MODIFIED: Normalize timestamps to end at 0 (starting from -3000)\n",
    "                normalized_timestamps = masked_timestamps - time_end  # This will make timestamps LongDurationVisual\n",
    "               \n",
    "                nan_mask = ~np.isnan(masked_average_diameter)\n",
    "                working_pupil_data = masked_average_diameter[nan_mask]\n",
    "                working_timestamps = normalized_timestamps[nan_mask]\n",
    "\n",
    "                # Skip trials with insufficient data\n",
    "                if len(working_pupil_data) < 50:\n",
    "                    print(f\"Skipping trial {trial_num} - insufficient data points: {len(working_pupil_data)}\")\n",
    "                    continue\n",
    "\n",
    "                # Blink detection\n",
    "                bfring = 50\n",
    "                blink_indices = np.where(masked_confidence < 0.4)[0]\n",
    "                blink_indices = (np.array(blink_indices)).flatten()\n",
    "                blinklist = []\n",
    "                for i in blink_indices:\n",
    "                    b = list(range((i-bfring),(i+bfring)))\n",
    "                    blinklist += b\n",
    "                for i in range(len(blinklist)):\n",
    "                    if blinklist[i] < 0:\n",
    "                        blinklist[i] = 0\n",
    "                final_blinks = np.unique(np.array(blinklist))\n",
    "                \n",
    "                permanent_finalblinks = []\n",
    "                for i in final_blinks:\n",
    "                    if i < len(working_pupil_data):\n",
    "                        permanent_finalblinks.append(i)\n",
    "                permanent_finalblinks = np.array(permanent_finalblinks)\n",
    "\n",
    "                # Insert NaNs at blink positions\n",
    "                for i in permanent_finalblinks:\n",
    "                    if i < len(working_pupil_data):\n",
    "                        working_pupil_data[i] = np.nan\n",
    "\n",
    "                # Interpolate missing data\n",
    "                if np.any(~np.isnan(working_pupil_data)):\n",
    "                    ok = ~np.isnan(working_pupil_data)\n",
    "                    xp = ok.ravel().nonzero()[0]\n",
    "                    fp = working_pupil_data[~np.isnan(working_pupil_data)]\n",
    "                    x = np.isnan(working_pupil_data).ravel().nonzero()[0]\n",
    "            \n",
    "                    if len(xp) > 0 and len(x) > 0:\n",
    "                        working_pupil_data[np.isnan(working_pupil_data)] = np.interp(x, xp, fp)\n",
    "                    elif len(x) > 0:\n",
    "                        working_pupil_data[np.isnan(working_pupil_data)] = 0\n",
    "                else:\n",
    "                    print(f\"Warning: All data is NaN in trial {trial_num}. Filling with zeros.\")\n",
    "                    working_pupil_data.fill(0)\n",
    "\n",
    "                # Smoothing data using savgol filter\n",
    "                filtered_pupil_data = savgol_filter(working_pupil_data, 11, 3)\n",
    "                \n",
    "                # Calculate baseline from first 50 data points \n",
    "                # Note: This is now the earliest part of the -3000 to 0 ms window\n",
    "                baseline = filtered_pupil_data[0:50]\n",
    "                avg = stats.mean(baseline)\n",
    "                baseline_corrected = filtered_pupil_data - avg\n",
    "                \n",
    "                baseline_LongDurationVisual = filtered_pupil_data[0:50]\n",
    "                avg_LongDurationVisual = stats.mean(baseline_LongDurationVisual)\n",
    "                baseline_corrected_LongDurationVisual = filtered_pupil_data - avg_LongDurationVisual\n",
    "                \n",
    "                baseline_ShortDurationVisual = filtered_pupil_data[0:50]\n",
    "                avg_ShortDurationVisual = stats.mean(baseline_ShortDurationVisual)\n",
    "                baseline_corrected_ShortDurationVisual = filtered_pupil_data - avg_ShortDurationVisual\n",
    "                \n",
    "                baseline_avg_array.append(avg)\n",
    "                \n",
    "                # Store trial data and baseline by condition\n",
    "                if condition_label == \"LongDurationVisual\":\n",
    "                    LongDurationVisual_condition_trials.append({\n",
    "                        'trial_num': trial_num,\n",
    "                        'data': baseline_corrected_LongDurationVisual,\n",
    "                        'timestamps': working_timestamps.copy(),\n",
    "                        'duration': trial_duration\n",
    "                    })\n",
    "                    LongDurationVisual_condition_baselines.append(avg)\n",
    "                elif condition_label == \"ShortDurationVisual\":\n",
    "                    ShortDurationVisual_condition_trials.append({\n",
    "                        'trial_num': trial_num,\n",
    "                        'data': baseline_corrected_ShortDurationVisual,\n",
    "                        'timestamps': working_timestamps.copy(),\n",
    "                        'duration': trial_duration\n",
    "                    })\n",
    "                    ShortDurationVisual_condition_baselines.append(avg)\n",
    "        \n",
    "        # Convert baseline lists to numpy arrays\n",
    "        LongDurationVisual_condition_baselines = np.array(LongDurationVisual_condition_baselines)\n",
    "        ShortDurationVisual_condition_baselines = np.array(ShortDurationVisual_condition_baselines)\n",
    "        baseline_avg_array = np.array(baseline_avg_array)\n",
    "        \n",
    "        # Print summary of the data for this participant\n",
    "        print(f\"  Number of LongDurationVisual trials: {len(LongDurationVisual_condition_trials)}\")\n",
    "        print(f\"  Number of ShortDurationVisual trials: {len(ShortDurationVisual_condition_trials)}\")\n",
    "        \n",
    "        # Function to resample trial data\n",
    "        def resample_trial_data(trials, target_length=500):\n",
    "            \"\"\"Resample all trials to a consistent length for averaging\"\"\"\n",
    "            resampled_data = []\n",
    "            \n",
    "            for trial in trials:\n",
    "                data = trial['data']\n",
    "                if len(data) < 2:  # Skip trials with insufficient data\n",
    "                    continue\n",
    "                    \n",
    "                # Create interpolation function\n",
    "                x_original = np.linspace(0, 1, len(data))\n",
    "                x_new = np.linspace(0, 1, target_length)\n",
    "                interpolator = interp1d(x_original, data, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "                \n",
    "                # Resample data\n",
    "                resampled = interpolator(x_new)\n",
    "                resampled_data.append(resampled)\n",
    "            \n",
    "            return np.array(resampled_data)\n",
    "        \n",
    "        # Resample and average trials for this participant\n",
    "        participant_LongDurationVisual_mean = None\n",
    "        participant_ShortDurationVisual_mean = None\n",
    "        \n",
    "        if LongDurationVisual_condition_trials:\n",
    "            LongDurationVisual_resampled = resample_trial_data([t for t in LongDurationVisual_condition_trials if len(t['data']) >= 2], target_length)\n",
    "            if len(LongDurationVisual_resampled) > 0:\n",
    "                participant_LongDurationVisual_mean = np.mean(LongDurationVisual_resampled, axis=0)\n",
    "                participant_LongDurationVisual_std = np.std(LongDurationVisual_resampled, axis=0)\n",
    "                participant_LongDurationVisual_sem = participant_LongDurationVisual_std / np.sqrt(len(LongDurationVisual_resampled))\n",
    "                \n",
    "                all_LongDurationVisual_resampled.append(participant_LongDurationVisual_mean)\n",
    "                print(f\"  Resampled LongDurationVisual data shape: {LongDurationVisual_resampled.shape}\")\n",
    "            else:\n",
    "                print(\"  No valid LongDurationVisual trials for resampling\")\n",
    "\n",
    "        if ShortDurationVisual_condition_trials:\n",
    "            ShortDurationVisual_resampled = resample_trial_data([t for t in ShortDurationVisual_condition_trials if len(t['data']) >= 2], target_length)\n",
    "            if len(ShortDurationVisual_resampled) > 0:\n",
    "                participant_ShortDurationVisual_mean = np.mean(ShortDurationVisual_resampled, axis=0)\n",
    "                participant_ShortDurationVisual_std = np.std(ShortDurationVisual_resampled, axis=0)\n",
    "                participant_ShortDurationVisual_sem = participant_ShortDurationVisual_std / np.sqrt(len(ShortDurationVisual_resampled))\n",
    "                \n",
    "                all_ShortDurationVisual_resampled.append(participant_ShortDurationVisual_mean)\n",
    "                print(f\"  Resampled ShortDurationVisual data shape: {ShortDurationVisual_resampled.shape}\")\n",
    "            else:\n",
    "                print(\"  No valid ShortDurationVisual trials for resampling\")\n",
    "        \n",
    "        # Calculate average durations for each condition\n",
    "        avg_long_duration = np.mean([t['duration'] for t in LongDurationVisual_condition_trials]) if LongDurationVisual_condition_trials else np.nan\n",
    "        avg_short_duration = np.mean([t['duration'] for t in ShortDurationVisual_condition_trials]) if ShortDurationVisual_condition_trials else np.nan\n",
    "        \n",
    "        # NEW: Store participant-level statistics\n",
    "        participant_stats[participant_id] = {\n",
    "            \"LongDurationVisual_trials_count\": len(LongDurationVisual_condition_trials),\n",
    "            \"ShortDurationVisual_trials_count\": len(ShortDurationVisual_condition_trials),\n",
    "            \"LongDurationVisual_baseline_mean\": np.mean(LongDurationVisual_condition_baselines) if len(LongDurationVisual_condition_baselines) > 0 else np.nan,\n",
    "            \"LongDurationVisual_baseline_std\": np.std(LongDurationVisual_condition_baselines) if len(LongDurationVisual_condition_baselines) > 0 else np.nan,\n",
    "            \"ShortDurationVisual_baseline_mean\": np.mean(ShortDurationVisual_condition_baselines) if len(ShortDurationVisual_condition_baselines) > 0 else np.nan,\n",
    "            \"ShortDurationVisual_baseline_std\": np.std(ShortDurationVisual_condition_baselines) if len(ShortDurationVisual_condition_baselines) > 0 else np.nan,\n",
    "            \"LongDurationVisual_mean\": participant_LongDurationVisual_mean,\n",
    "            \"LongDurationVisual_std\": participant_LongDurationVisual_std if 'participant_LongDurationVisual_std' in locals() else None,\n",
    "            \"LongDurationVisual_sem\": participant_LongDurationVisual_sem if 'participant_LongDurationVisual_sem' in locals() else None,\n",
    "            \"ShortDurationVisual_mean\": participant_ShortDurationVisual_mean,\n",
    "            \"ShortDurationVisual_std\": participant_ShortDurationVisual_std if 'participant_ShortDurationVisual_std' in locals() else None,\n",
    "            \"ShortDurationVisual_sem\": participant_ShortDurationVisual_sem if 'participant_ShortDurationVisual_sem' in locals() else None,\n",
    "            \"avg_long_duration_ms\": avg_long_duration,\n",
    "            \"avg_short_duration_ms\": avg_short_duration\n",
    "        }\n",
    "        \n",
    "        # Store data for this participant\n",
    "        all_participants_LongDurationVisual_baselines.extend(LongDurationVisual_condition_baselines)\n",
    "        all_participants_ShortDurationVisual_baselines.extend(ShortDurationVisual_condition_baselines)\n",
    "        all_participants_baseline_avg.extend(baseline_avg_array)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing participant {participant_file}: {e}\")\n",
    "\n",
    "# Convert participant data to numpy arrays\n",
    "all_LongDurationVisual_resampled = np.array(all_LongDurationVisual_resampled)\n",
    "all_ShortDurationVisual_resampled = np.array(all_ShortDurationVisual_resampled)\n",
    "all_participants_LongDurationVisual_baselines = np.array(all_participants_LongDurationVisual_baselines)\n",
    "all_participants_ShortDurationVisual_baselines = np.array(all_participants_ShortDurationVisual_baselines)\n",
    "all_participants_baseline_avg = np.array(all_participants_baseline_avg)\n",
    "\n",
    "print(f\"\\nProcessed data from {len(all_LongDurationVisual_resampled)} participants for LongDurationVisual\")\n",
    "print(f\"Processed data from {len(all_ShortDurationVisual_resampled)} participants for ShortDurationVisual\")\n",
    "\n",
    "# Calculate grand averages across participants\n",
    "if len(all_LongDurationVisual_resampled) > 0:\n",
    "    LongDurationVisual_grand_mean = np.mean(all_LongDurationVisual_resampled, axis=0)\n",
    "    LongDurationVisual_grand_std = np.std(all_LongDurationVisual_resampled, axis=0)\n",
    "    LongDurationVisual_grand_sem = LongDurationVisual_grand_std / np.sqrt(len(all_LongDurationVisual_resampled))\n",
    "else:\n",
    "    print(\"Warning: No valid LongDurationVisual data across participants\")\n",
    "    \n",
    "if len(all_ShortDurationVisual_resampled) > 0:\n",
    "    ShortDurationVisual_grand_mean = np.mean(all_ShortDurationVisual_resampled, axis=0)\n",
    "    ShortDurationVisual_grand_std = np.std(all_ShortDurationVisual_resampled, axis=0)\n",
    "    ShortDurationVisual_grand_sem = ShortDurationVisual_grand_std / np.sqrt(len(all_ShortDurationVisual_resampled))\n",
    "else:\n",
    "    print(\"Warning: No valid ShortDurationVisual data across participants\")\n",
    "\n",
    "# NEW: Export participant-level summary statistics to CSV\n",
    "participant_summary_data = []\n",
    "for participant_id, stats_dict in participant_stats.items():\n",
    "    # Calculate summary statistics for this participant\n",
    "    LongDurationVisual_mean_value = np.nanmean(stats_dict[\"LongDurationVisual_mean\"]) if stats_dict[\"LongDurationVisual_mean\"] is not None else np.nan\n",
    "    LongDurationVisual_max_value = np.nanmax(stats_dict[\"LongDurationVisual_mean\"]) if stats_dict[\"LongDurationVisual_mean\"] is not None else np.nan\n",
    "    LongDurationVisual_min_value = np.nanmin(stats_dict[\"LongDurationVisual_mean\"]) if stats_dict[\"LongDurationVisual_mean\"] is not None else np.nan\n",
    "    \n",
    "    ShortDurationVisual_mean_value = np.nanmean(stats_dict[\"ShortDurationVisual_mean\"]) if stats_dict[\"ShortDurationVisual_mean\"] is not None else np.nan\n",
    "    ShortDurationVisual_max_value = np.nanmax(stats_dict[\"ShortDurationVisual_mean\"]) if stats_dict[\"ShortDurationVisual_mean\"] is not None else np.nan\n",
    "    ShortDurationVisual_min_value = np.nanmin(stats_dict[\"ShortDurationVisual_mean\"]) if stats_dict[\"ShortDurationVisual_mean\"] is not None else np.nan\n",
    "    \n",
    "    participant_summary_data.append({\n",
    "        \"participant_id\": participant_id,\n",
    "        \"LongDurationVisual_trials_count\": stats_dict[\"LongDurationVisual_trials_count\"],\n",
    "        \"ShortDurationVisual_trials_count\": stats_dict[\"ShortDurationVisual_trials_count\"],\n",
    "        \"LongDurationVisual_baseline_mean\": stats_dict[\"LongDurationVisual_baseline_mean\"],\n",
    "        \"LongDurationVisual_baseline_std\": stats_dict[\"LongDurationVisual_baseline_std\"],\n",
    "        \"ShortDurationVisual_baseline_mean\": stats_dict[\"ShortDurationVisual_baseline_mean\"],\n",
    "        \"ShortDurationVisual_baseline_std\": stats_dict[\"ShortDurationVisual_baseline_std\"],\n",
    "        \"LongDurationVisual_response_mean\": LongDurationVisual_mean_value,\n",
    "        \"LongDurationVisual_response_max\": LongDurationVisual_max_value,\n",
    "        \"LongDurationVisual_response_min\": LongDurationVisual_min_value,\n",
    "        \"ShortDurationVisual_response_mean\": ShortDurationVisual_mean_value,\n",
    "        \"ShortDurationVisual_response_max\": ShortDurationVisual_max_value,\n",
    "        \"ShortDurationVisual_response_min\": ShortDurationVisual_min_value,\n",
    "        \"avg_long_duration_ms\": stats_dict[\"avg_long_duration_ms\"],\n",
    "        \"avg_short_duration_ms\": stats_dict[\"avg_short_duration_ms\"]\n",
    "    })\n",
    "\n",
    "# Save participant summary data to CSV\n",
    "participant_summary_df = pd.DataFrame(participant_summary_data)\n",
    "participant_summary_df.to_csv(\"pre_stimulus_participant_summary_statistics_duration_negative_only.csv\", index=False)\n",
    "print(\"Saved participant summary statistics to pre_stimulus_participant_summary_statistics_duration_negative_only.csv\")\n",
    "\n",
    "# MODIFIED: Create time axis from -3000 to 0 ms\n",
    "time_axis = np.linspace(-3000, 0, target_length)\n",
    "\n",
    "# Create DataFrames for time-series data\n",
    "LongDurationVisual_timeseries_data = {\"time_ms\": time_axis}\n",
    "ShortDurationVisual_timeseries_data = {\"time_ms\": time_axis}\n",
    "\n",
    "# Add grand mean and SEM to DataFrames\n",
    "if 'LongDurationVisual_grand_mean' in locals():\n",
    "    LongDurationVisual_timeseries_data[\"grand_mean\"] = LongDurationVisual_grand_mean\n",
    "    LongDurationVisual_timeseries_data[\"grand_std\"] = LongDurationVisual_grand_std\n",
    "    LongDurationVisual_timeseries_data[\"grand_sem\"] = LongDurationVisual_grand_sem\n",
    "\n",
    "if 'ShortDurationVisual_grand_mean' in locals():\n",
    "    ShortDurationVisual_timeseries_data[\"grand_mean\"] = ShortDurationVisual_grand_mean\n",
    "    ShortDurationVisual_timeseries_data[\"grand_std\"] = ShortDurationVisual_grand_std\n",
    "    ShortDurationVisual_timeseries_data[\"grand_sem\"] = ShortDurationVisual_grand_sem\n",
    "\n",
    "# Add individual participant data to DataFrames\n",
    "for participant_id, stats_dict in participant_stats.items():\n",
    "    if stats_dict[\"LongDurationVisual_mean\"] is not None:\n",
    "        LongDurationVisual_timeseries_data[f\"participant_{participant_id}\"] = stats_dict[\"LongDurationVisual_mean\"]\n",
    "    \n",
    "    if stats_dict[\"ShortDurationVisual_mean\"] is not None:\n",
    "        ShortDurationVisual_timeseries_data[f\"participant_{participant_id}\"] = stats_dict[\"ShortDurationVisual_mean\"]\n",
    "\n",
    "# Save time-series data to CSV\n",
    "LongDurationVisual_timeseries_df = pd.DataFrame(LongDurationVisual_timeseries_data)\n",
    "LongDurationVisual_timeseries_df.to_csv(\"pre_stimulus_LongDurationVisual_condition_timeseries_negative_only.csv\", index=False)\n",
    "print(\"Saved LongDurationVisual time-series data to pre_stimulus_LongDurationVisual_condition_timeseries_negative_only.csv\")\n",
    "\n",
    "ShortDurationVisual_timeseries_df = pd.DataFrame(ShortDurationVisual_timeseries_data)\n",
    "ShortDurationVisual_timeseries_df.to_csv(\"pre_stimulus_ShortDurationVisual_condition_timeseries_negative_only.csv\", index=False)\n",
    "print(\"Saved ShortDurationVisual time-series data to pre_stimulus_ShortDurationVisual_condition_timeseries_negative_only.csv\")\n",
    "\n",
    "# Export group-level summary statistics\n",
    "mean_LongDurationVisual_baseline = np.mean(all_participants_LongDurationVisual_baselines)\n",
    "std_LongDurationVisual_baseline = np.std(all_participants_LongDurationVisual_baselines)\n",
    "sem_LongDurationVisual_baseline = std_LongDurationVisual_baseline / np.sqrt(len(all_participants_LongDurationVisual_baselines))\n",
    "\n",
    "mean_ShortDurationVisual_baseline = np.mean(all_participants_ShortDurationVisual_baselines)\n",
    "std_ShortDurationVisual_baseline = np.std(all_participants_ShortDurationVisual_baselines)\n",
    "sem_ShortDurationVisual_baseline = std_ShortDurationVisual_baseline / np.sqrt(len(all_participants_ShortDurationVisual_baselines))\n",
    "\n",
    "# Calculate average durations across all trials for each condition\n",
    "avg_long_duration_all = np.mean([stats_dict[\"avg_long_duration_ms\"] for _, stats_dict in participant_stats.items() \n",
    "                               if not np.isnan(stats_dict[\"avg_long_duration_ms\"])])\n",
    "avg_short_duration_all = np.mean([stats_dict[\"avg_short_duration_ms\"] for _, stats_dict in participant_stats.items() \n",
    "                                if not np.isnan(stats_dict[\"avg_short_duration_ms\"])])\n",
    "\n",
    "group_summary_data = {\n",
    "    \"statistic\": [\"baseline_mean\", \"baseline_std\", \"baseline_sem\", \n",
    "                 \"response_mean\", \"response_std\", \"response_sem\",\n",
    "                 \"peak_response\", \"peak_time_ms\", \"participant_count\",\n",
    "                 \"median_split_value_ms\", \"avg_duration_ms\"],\n",
    "    \"LongDurationVisual_condition\": [\n",
    "        mean_LongDurationVisual_baseline,\n",
    "        std_LongDurationVisual_baseline,\n",
    "        sem_LongDurationVisual_baseline,\n",
    "        np.mean(LongDurationVisual_grand_mean) if 'LongDurationVisual_grand_mean' in locals() else np.nan,\n",
    "        np.mean(LongDurationVisual_grand_std) if 'LongDurationVisual_grand_std' in locals() else np.nan,\n",
    "        np.mean(LongDurationVisual_grand_sem) if 'LongDurationVisual_grand_sem' in locals() else np.nan,\n",
    "        np.max(LongDurationVisual_grand_mean) if 'LongDurationVisual_grand_mean' in locals() else np.nan,\n",
    "        time_axis[np.argmax(LongDurationVisual_grand_mean)] if 'LongDurationVisual_grand_mean' in locals() else np.nan,\n",
    "        len(all_LongDurationVisual_resampled),\n",
    "        median_duration,\n",
    "        avg_long_duration_all\n",
    "    ],\n",
    "    \"ShortDurationVisual_condition\": [\n",
    "        mean_ShortDurationVisual_baseline,\n",
    "        std_ShortDurationVisual_baseline,\n",
    "        sem_ShortDurationVisual_baseline,\n",
    "        np.mean(ShortDurationVisual_grand_mean) if 'ShortDurationVisual_grand_mean' in locals() else np.nan,\n",
    "        np.mean(ShortDurationVisual_grand_std) if 'ShortDurationVisual_grand_std' in locals() else np.nan,\n",
    "        np.mean(ShortDurationVisual_grand_sem) if 'ShortDurationVisual_grand_sem' in locals() else np.nan,\n",
    "        np.max(ShortDurationVisual_grand_mean) if 'ShortDurationVisual_grand_mean' in locals() else np.nan,\n",
    "        time_axis[np.argmax(ShortDurationVisual_grand_mean)] if 'ShortDurationVisual_grand_mean' in locals() else np.nan,\n",
    "        len(all_ShortDurationVisual_resampled),\n",
    "        median_duration,\n",
    "        avg_short_duration_all\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save group summary data to CSV\n",
    "group_summary_df = pd.DataFrame(group_summary_data)\n",
    "group_summary_df.to_csv(\"pre_stimulus_group_summary_statistics_duration_negative_only.csv\", index=False)\n",
    "print(\"Saved group summary statistics to pre_stimulus_group_summary_statistics_duration_negative_only.csv\")\n",
    "\n",
    "# Calculate percentage change for each condition\n",
    "if 'LongDurationVisual_grand_mean' in locals() and 'ShortDurationVisual_grand_mean' in locals():\n",
    "    # Calculate percentage change for each participant and save to CSV\n",
    "    percentage_change_data = {\"time_ms\": time_axis}\n",
    "    \n",
    "    # Add grand mean percentage changes\n",
    "    mean_LongDurationVisual_baseline = np.mean(all_participants_LongDurationVisual_baselines)\n",
    "    mean_ShortDurationVisual_baseline = np.mean(all_participants_ShortDurationVisual_baselines)\n",
    "    \n",
    "    LongDurationVisual_percent_change = (LongDurationVisual_grand_mean / mean_LongDurationVisual_baseline) * 100\n",
    "    ShortDurationVisual_percent_change = (ShortDurationVisual_grand_mean / mean_ShortDurationVisual_baseline) * 100\n",
    "    \n",
    "    percentage_change_data[\"LongDurationVisual_percent_change\"] = LongDurationVisual_percent_change\n",
    "    percentage_change_data[\"ShortDurationVisual_percent_change\"] = ShortDurationVisual_percent_change\n",
    "    \n",
    "    # Save percentage change data to CSV\n",
    "    percentage_change_df = pd.DataFrame(percentage_change_data)\n",
    "    percentage_change_df.to_csv(\"pre_stimulus_percentage_change_timeseries_duration_negative_only.csv\", index=False)\n",
    "    print(\"Saved percentage change time-series to pre_stimulus_percentage_change_timeseries_duration_negative_only.csv\")\n",
    "\n",
    "# Create plots with grand averages and SEM\n",
    "if 'LongDurationVisual_grand_mean' in locals() and 'ShortDurationVisual_grand_mean' in locals():\n",
    "    # Plot 1: Average Pupil Size Comparison\n",
    "    f = plt.figure(8)\n",
    "    f.set_figheight(10) \n",
    "    f.set_figwidth(20)  \n",
    "    \n",
    "    plt.plot(time_axis, LongDurationVisual_grand_mean, 'bo', label=\"Long Duration\")\n",
    "    plt.fill_between(time_axis, \n",
    "                     LongDurationVisual_grand_mean - LongDurationVisual_grand_sem, \n",
    "                     LongDurationVisual_grand_mean + LongDurationVisual_grand_sem, \n",
    "                     color='blue', alpha=0.2)\n",
    "    \n",
    "    plt.plot(time_axis, ShortDurationVisual_grand_mean, 'ro', label=\"Short Duration\")\n",
    "    plt.fill_between(time_axis, \n",
    "                     ShortDurationVisual_grand_mean - ShortDurationVisual_grand_sem, \n",
    "                     ShortDurationVisual_grand_mean + ShortDurationVisual_grand_sem, \n",
    "                     color='red', alpha=0.2)\n",
    "    \n",
    "    plt.xlabel(\"Time in milliseconds (relative to stimulus onset)\", fontsize=\"20\")\n",
    "    plt.ylabel(\"Pupil Diameter in arbitrary units\", fontsize=\"20\")\n",
    "    plt.legend(loc=\"upper left\", fontsize=\"16\") \n",
    "    plt.title(\"Average Pre-Stimulus Pupil Size Comparison-ShortDurationVisual vs LongDurationVisual (Negative Trials Only)\")\n",
    "    plt.axvline(x=0, color='k', linestyle='--')  # Mark the stimulus onset\n",
    "    plt.savefig(\"pre_stimulus_pupil_time_series_comparison_v_negative_only.png\")\n",
    "\n",
    "    # Plot 2: Subtractive Baseline Corrected Pupil Size Series\n",
    "        # Plot 2: Subtractive Baseline Corrected Pupil Size Series\n",
    "    f = plt.figure(11)\n",
    "    f.set_figheight(10)\n",
    "    f.set_figwidth(20)\n",
    "    \n",
    "    plt.plot(time_axis, ShortDurationVisual_grand_mean, \"bo\", label=\"ShortDurationVisual\")\n",
    "    plt.fill_between(time_axis, \n",
    "                     ShortDurationVisual_grand_mean - ShortDurationVisual_grand_sem, \n",
    "                     ShortDurationVisual_grand_mean + ShortDurationVisual_grand_sem, \n",
    "                     color='blue', alpha=0.2)\n",
    "    \n",
    "    plt.plot(time_axis, LongDurationVisual_grand_mean, \"ro\", label=\"LongDurationVisual\")\n",
    "    plt.fill_between(time_axis, \n",
    "                     LongDurationVisual_grand_mean - LongDurationVisual_grand_sem, \n",
    "                     LongDurationVisual_grand_mean + LongDurationVisual_grand_sem, \n",
    "                     color='red', alpha=0.2)\n",
    "    \n",
    "    plt.xlabel(\"Time in milliseconds (relative to stimulus onset)\", fontsize=\"20\")\n",
    "    plt.ylabel(\"Change in Pupil size over time wrt Baseline size\", fontsize=\"20\")\n",
    "    plt.legend(loc=\"upper left\", fontsize=\"16\")\n",
    "    plt.title(\"Pre-Stimulus Subtractive Baseline Corrected Pupil Size Series\")\n",
    "    plt.axvline(x=0, color='k', linestyle='--')  # Mark the stimulus onset\n",
    "    plt.savefig(\"pre_stimulus_baseline_corrected_pupil_size_v.png\")\n",
    "\n",
    "    # Plot 3: Percentage Change\n",
    "    # Calculate percentage change for grand means\n",
    "    mean_ShortDurationVisual_baseline = np.mean(all_participants_ShortDurationVisual_baselines)\n",
    "    mean_LongDurationVisual_baseline = np.mean(all_participants_LongDurationVisual_baselines)\n",
    "    \n",
    "    ShortDurationVisual_percent_change = (ShortDurationVisual_grand_mean / mean_ShortDurationVisual_baseline) * 100\n",
    "    LongDurationVisual_percent_change = (LongDurationVisual_grand_mean / mean_LongDurationVisual_baseline) * 100\n",
    "    \n",
    "    # Calculate percentage change for each participant\n",
    "    ShortDurationVisual_percent_changes = []\n",
    "    LongDurationVisual_percent_changes = []\n",
    "    \n",
    "    for i in range(len(all_ShortDurationVisual_resampled)):\n",
    "        ShortDurationVisual_percent_changes.append((all_ShortDurationVisual_resampled[i] / mean_ShortDurationVisual_baseline) * 100)\n",
    "    \n",
    "    for i in range(len(all_LongDurationVisual_resampled)):\n",
    "        LongDurationVisual_percent_changes.append((all_LongDurationVisual_resampled[i] / mean_LongDurationVisual_baseline) * 100)\n",
    "    \n",
    "    # Calculate SEM for percentage changes\n",
    "    ShortDurationVisual_sem = np.std(np.array(ShortDurationVisual_percent_changes), axis=0) / np.sqrt(len(ShortDurationVisual_percent_changes))\n",
    "    LongDurationVisual_sem = np.std(np.array(LongDurationVisual_percent_changes), axis=0) / np.sqrt(len(LongDurationVisual_percent_changes))\n",
    "    \n",
    "    f = plt.figure(12)\n",
    "    f.set_figheight(10)\n",
    "    f.set_figwidth(20)\n",
    "    \n",
    "    plt.plot(time_axis, ShortDurationVisual_percent_change, 'bo', label=\"ShortDurationVisual\")\n",
    "    plt.fill_between(time_axis, \n",
    "                     ShortDurationVisual_percent_change - ShortDurationVisual_sem, \n",
    "                     ShortDurationVisual_percent_change + ShortDurationVisual_sem, \n",
    "                     color='blue', alpha=0.2)\n",
    "    \n",
    "    plt.plot(time_axis, LongDurationVisual_percent_change, 'ro', label=\"LongDurationVisual\")\n",
    "    plt.fill_between(time_axis, \n",
    "                     LongDurationVisual_percent_change - LongDurationVisual_sem, \n",
    "                     LongDurationVisual_percent_change + LongDurationVisual_sem, \n",
    "                     color='red', alpha=0.2)\n",
    "    \n",
    "    plt.xlabel(\"Time in milliseconds (relative to stimulus onset)\", fontsize=\"20\")\n",
    "    plt.ylabel(\"Average Percentage Change in Pupil Size from the Baseline Size\", fontsize=\"20\")\n",
    "    plt.legend(loc=\"upper left\", fontsize=\"16\")\n",
    "    plt.title(\"Pre-Stimulus Average Percentage Change in Pupil Size\")\n",
    "    plt.axvline(x=0, color='k', linestyle='--')  # Mark the stimulus onset\n",
    "    plt.savefig(\"pre_stimulus_percentage_change_pupil_size_v.png\")\n",
    "\n",
    "    # Plot 4: Z-scored data\n",
    "    # Combine ShortDurationVisual and LongDurationVisual means into one array\n",
    "    final_reward = list(ShortDurationVisual_grand_mean)\n",
    "    final_reward.extend(list(LongDurationVisual_grand_mean))\n",
    "    mean_final_reward = stats.mean(final_reward)\n",
    "    std_final = stats.stdev(final_reward)\n",
    "\n",
    "    # Calculate z-scores for all data points\n",
    "    zscored = []\n",
    "    for i in range(len(final_reward)):\n",
    "        z = (final_reward[i] - mean_final_reward) / std_final\n",
    "        zscored.append(z)\n",
    "\n",
    "    # Split the z-scored data back into ShortDurationVisual and LongDurationVisuals\n",
    "    ShortDurationVisual_z = np.array(zscored[:target_length])  # First half is ShortDurationVisual\n",
    "    LongDurationVisual_z = np.array(zscored[target_length:])  # Second half is LongDurationVisual\n",
    "\n",
    "    # Calculate baseline z-scores (first 50 points)\n",
    "    baseline_ShortDurationVisual_z = ShortDurationVisual_z[0:50]\n",
    "    baseline_LongDurationVisual_z = LongDurationVisual_z[0:50]\n",
    "\n",
    "    # Calculate mean baseline z-scores\n",
    "    mean_base_ShortDurationVisual = stats.mean(baseline_ShortDurationVisual_z)\n",
    "    mean_base_LongDurationVisual = stats.mean(baseline_LongDurationVisual_z)\n",
    "\n",
    "    # Calculate baseline-corrected z-scores\n",
    "    final_z_b_ShortDurationVisual = ShortDurationVisual_z - mean_base_ShortDurationVisual\n",
    "    final_z_b_LongDurationVisual = LongDurationVisual_z - mean_base_LongDurationVisual\n",
    "\n",
    "    # Calculate percentage change for z-scores\n",
    "    percentage_ShortDurationVisual = (final_z_b_ShortDurationVisual / abs(mean_base_ShortDurationVisual)) * 100 if mean_base_ShortDurationVisual != 0 else np.zeros_like(final_z_b_ShortDurationVisual)\n",
    "    percentage_LongDurationVisual = (final_z_b_LongDurationVisual / abs(mean_base_LongDurationVisual)) * 100 if mean_base_LongDurationVisual != 0 else np.zeros_like(final_z_b_LongDurationVisual)\n",
    "    \n",
    "    # Calculate z-scores for each participant for SEM\n",
    "    all_ShortDurationVisual_z = []\n",
    "    all_LongDurationVisual_z = []\n",
    "    \n",
    "    for i in range(len(all_ShortDurationVisual_resampled)):\n",
    "        # Z-score calculation for this participant\n",
    "        participant_data = list(all_ShortDurationVisual_resampled[i])\n",
    "        participant_data.extend(list(all_LongDurationVisual_resampled[i]))\n",
    "        mean_participant = stats.mean(participant_data)\n",
    "        std_participant = stats.stdev(participant_data)\n",
    "        \n",
    "        # Calculate z-scores\n",
    "        participant_z = []\n",
    "        for val in participant_data:\n",
    "            z = (val - mean_participant) / std_participant\n",
    "            participant_z.append(z)\n",
    "        \n",
    "        # Split and store\n",
    "        all_ShortDurationVisual_z.append(participant_z[:target_length])\n",
    "        all_LongDurationVisual_z.append(participant_z[target_length:])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_ShortDurationVisual_z = np.array(all_ShortDurationVisual_z)\n",
    "    all_LongDurationVisual_z = np.array(all_LongDurationVisual_z)\n",
    "    \n",
    "    # Calculate baseline-corrected z-scores for each participant\n",
    "    all_final_z_b_ShortDurationVisual = []\n",
    "    all_final_z_b_LongDurationVisual = []\n",
    "    all_percentage_ShortDurationVisual = []\n",
    "    all_percentage_LongDurationVisual = []\n",
    "    \n",
    "    for i in range(len(all_ShortDurationVisual_z)):\n",
    "        # Calculate participant's baseline\n",
    "        participant_baseline_short = np.mean(all_ShortDurationVisual_z[i][0:50])\n",
    "        participant_baseline_long = np.mean(all_LongDurationVisual_z[i][0:50])\n",
    "        \n",
    "        # Calculate baseline-corrected z-scores\n",
    "        z_b_short = all_ShortDurationVisual_z[i] - participant_baseline_short\n",
    "        z_b_long = all_LongDurationVisual_z[i] - participant_baseline_long\n",
    "        \n",
    "        all_final_z_b_ShortDurationVisual.append(z_b_short)\n",
    "        all_final_z_b_LongDurationVisual.append(z_b_long)\n",
    "        \n",
    "        \n",
    "        # Calculate percentage change\n",
    "        pct_short = (z_b_short / abs(participant_baseline_short)) * 100 if participant_baseline_short != 0 else np.zeros_like(z_b_short)\n",
    "        pct_long = (z_b_long / abs(participant_baseline_long)) * 100 if participant_baseline_long != 0 else np.zeros_like(z_b_long)\n",
    "        \n",
    "        \n",
    "        all_percentage_ShortDurationVisual.append(pct_short)\n",
    "        all_percentage_LongDurationVisual.append(pct_long)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_percentage_ShortDurationVisual = np.array(all_percentage_ShortDurationVisual)\n",
    "    all_percentage_LongDurationVisual = np.array(all_percentage_LongDurationVisual)\n",
    "    \n",
    "    # Calculate SEM for percentage change\n",
    "    percentage_ShortDurationVisual_sem = np.std(all_percentage_ShortDurationVisual, axis=0) / np.sqrt(len(all_percentage_ShortDurationVisual))\n",
    "    percentage_LongDurationVisual_sem = np.std(all_percentage_LongDurationVisual, axis=0) / np.sqrt(len(all_percentage_LongDurationVisual))\n",
    "    \n",
    "    # For original z-scores (maintain the existing code)\n",
    "    ShortDurationVisual_z_sem = np.std(all_ShortDurationVisual_z, axis=0) / np.sqrt(len(all_ShortDurationVisual_z))\n",
    "    LongDurationVisual_z_sem = np.std(all_LongDurationVisual_z, axis=0) / np.sqrt(len(all_LongDurationVisual_z))\n",
    "    \n",
    "    # NEW: Save z-scored data to CSV\n",
    "    zscored_data = {\n",
    "        \"time_ms\": time_axis,\n",
    "        \"ShortDurationVisual_zscore\": final_z_b_ShortDurationVisual,\n",
    "        \"LongDurationVisual_zscore\": final_z_b_LongDurationVisual,\n",
    "        \"ShortDurationVisual_percentage\": percentage_ShortDurationVisual,\n",
    "        \"LongDurationVisual_percentage\": percentage_LongDurationVisual\n",
    "    }\n",
    "    \n",
    "    zscored_df = pd.DataFrame(zscored_data)\n",
    "    zscored_df.to_csv(\"zscored_data_v.csv\", index=False)\n",
    "    print(\"Saved z-scored data to zscored_data_v.csv\")\n",
    "\n",
    "  \n",
    "    \n",
    "    # Plot for percentage change in Z-scores\n",
    "    \n",
    "    f = plt.figure(14)\n",
    "    f.set_figheight(10)\n",
    "    f.set_figwidth(20)\n",
    "    \n",
    "    plt.plot(time_axis, percentage_ShortDurationVisual, 'bo', label=\"ShortDurationVisual\")\n",
    "    plt.fill_between(time_axis, \n",
    "                     percentage_ShortDurationVisual - percentage_ShortDurationVisual_sem, \n",
    "                     percentage_ShortDurationVisual + percentage_ShortDurationVisual_sem, \n",
    "                     color='blue', alpha=0.2)\n",
    "    \n",
    "    plt.plot(time_axis, percentage_LongDurationVisual, 'ro', label=\"LongDurationVisual\")\n",
    "    plt.fill_between(time_axis, \n",
    "                     percentage_LongDurationVisual - percentage_LongDurationVisual_sem, \n",
    "                     percentage_LongDurationVisual + percentage_LongDurationVisual_sem, \n",
    "                     color='red', alpha=0.2)\n",
    "    \n",
    "    plt.xlabel(\"Time in milliseconds\", fontsize=\"20\")\n",
    "    plt.ylabel(\"Average Percentage Change in Pupil Size (z-scored)\", fontsize=\"20\")\n",
    "    plt.legend(loc=\"upper left\", fontsize=\"16\")\n",
    "    plt.title(\"Average Percentage Change in Pupil Size (z-scored)\")\n",
    "    # Set y-axis limits and ticks\n",
    "    plt.ylim(-700, 450)\n",
    "    plt.yticks(np.arange(-700, 451, 50))  # -350, -600, ..., 100\n",
    "    \n",
    "    plt.savefig(\"zscored_percentage_change_v.png\")\n",
    "    \n",
    "    '''\n",
    "    f = plt.figure(figsize=(3, 2.5))  # Small figure\n",
    "    plt.plot(time_axis, percentage_ShortDurationVisual, 'bo', label=\"Short\", linewidth=1)\n",
    "    plt.fill_between(time_axis, \n",
    "                 percentage_ShortDurationVisual - percentage_ShortDurationVisual_sem, \n",
    "                 percentage_ShortDurationVisual + percentage_ShortDurationVisual_sem, \n",
    "                 color='blue', alpha=0.2)\n",
    "\n",
    "    plt.plot(time_axis, percentage_LongDurationVisual, 'ro', label=\"Long\", linewidth=1)\n",
    "    plt.fill_between(time_axis, \n",
    "                 percentage_LongDurationVisual - percentage_LongDurationVisual_sem, \n",
    "                 percentage_LongDurationVisual + percentage_LongDurationVisual_sem, \n",
    "                 color='red', alpha=0.2)\n",
    "\n",
    "    # Use smaller but readable fonts\n",
    "    plt.xlabel(\"Time (ms)\", fontsize=8)\n",
    "    plt.ylabel(\"% Change in Pupil Size\", fontsize=8)\n",
    "    plt.title(\"% Change in Pupil Size (Visual)\", fontsize=9)\n",
    "    plt.legend(loc=\"lower left\", fontsize=6, frameon=False)\n",
    "\n",
    "    # Axis customization\n",
    "    plt.ylim(-450, 150)\n",
    "    plt.yticks(np.arange(-450, 151, 150), fontsize=6)\n",
    "    plt.xticks(fontsize=6)\n",
    "\n",
    "    # Tight layout for small space and clean export\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"small_zscore_plot.png\", dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Plot 5: Histogram of baseline averages\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    ax.hist(all_participants_baseline_avg, bins=20, alpha=0.7, label=\"All trials\")\n",
    "    ax.hist(all_participants_ShortDurationVisual_baselines, bins=20, alpha=0.5, label=\"ShortDurationVisual\")\n",
    "    ax.hist(all_participants_LongDurationVisual_baselines, bins=20, alpha=0.5, label=\"LongDurationVisual\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Baseline Pupil Diameter Distribution by Condition\")\n",
    "    ax.set_xlabel(\"Baseline Pupil Diameter (arbitrary units)\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    plt.savefig(\"baseline_diameter_histogram_v.png\")\n",
    "    \n",
    "    # Plot 6: Average pupil responses with SEM\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    ax.plot(time_axis, ShortDurationVisual_grand_mean, label=\"ShortDurationVisual\", color=\"blue\")\n",
    "    ax.fill_between(time_axis, \n",
    "                    ShortDurationVisual_grand_mean - ShortDurationVisual_grand_sem, \n",
    "                    ShortDurationVisual_grand_mean + ShortDurationVisual_grand_sem, \n",
    "                    color=\"blue\", alpha=0.2)\n",
    "    \n",
    "    ax.plot(time_axis, LongDurationVisual_grand_mean, label=\"LongDurationVisual\", color=\"red\")\n",
    "    ax.fill_between(time_axis, \n",
    "                    LongDurationVisual_grand_mean - LongDurationVisual_grand_sem, \n",
    "                    LongDurationVisual_grand_mean + LongDurationVisual_grand_sem, \n",
    "                    color=\"red\", alpha=0.2)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_title(\"Average Pupil Response by Condition with SEM\")\n",
    "    ax.set_xlabel(\"Time (ms)\")\n",
    "    ax.set_ylabel(\"Baseline-corrected Pupil Diameter\")\n",
    "    plt.savefig(\"average_pupil_response_with_sem_v.png\")\n",
    "\n",
    "    # NEW: Export additional statistical measurements\n",
    "    # Calculate peak values and time-to-peak\n",
    "    ShortDurationVisual_peak_value = np.max(ShortDurationVisual_grand_mean)\n",
    "    ShortDurationVisual_peak_time = time_axis[np.argmax(ShortDurationVisual_grand_mean)]\n",
    "    \n",
    "    LongDurationVisual_peak_value = np.max(LongDurationVisual_grand_mean)\n",
    "    LongDurationVisual_peak_time = time_axis[np.argmax(LongDurationVisual_grand_mean)]\n",
    "    \n",
    "    # Area under the curve (simple calculation)\n",
    "    ShortDurationVisual_auc = np.trapz(ShortDurationVisual_grand_mean, time_axis)\n",
    "    LongDurationVisual_auc = np.trapz(LongDurationVisual_grand_mean, time_axis)\n",
    "    \n",
    "    # Export these additional metrics\n",
    "    additional_metrics = {\n",
    "        \"metric\": [\"peak_value\", \"peak_time_ms\", \"area_under_curve\"],\n",
    "        \"ShortDurationVisual\": [ShortDurationVisual_peak_value, ShortDurationVisual_peak_time, ShortDurationVisual_auc],\n",
    "        \"LongDurationVisual\": [LongDurationVisual_peak_value, LongDurationVisual_peak_time, LongDurationVisual_auc]\n",
    "    }\n",
    "    \n",
    "    additional_metrics_df = pd.DataFrame(additional_metrics)\n",
    "    additional_metrics_df.to_csv(\"additional_pupil_metrics_v.csv\", index=False)\n",
    "    print(\"Saved additional pupil response metrics to additional_pupil_metrics_v.csv\")\n",
    "    \n",
    "    # NEW: Save raw trial data counts\n",
    "    trial_counts = {\n",
    "        \"condition\": [\"ShortDurationVisual\", \"LongDurationVisual\"],\n",
    "        \"trial_count\": [len(all_participants_ShortDurationVisual_baselines), len(all_participants_LongDurationVisual_baselines)],\n",
    "        \"participant_count\": [len(all_ShortDurationVisual_resampled), len(all_LongDurationVisual_resampled)]\n",
    "    }\n",
    "    \n",
    "    trial_counts_df = pd.DataFrame(trial_counts)\n",
    "    trial_counts_df.to_csv(\"trial_counts_v.csv\", index=False)\n",
    "    print(\"Saved trial count data to trial_counts_v.csv\")\n",
    "\n",
    "# NEW: Create a comprehensive summary report with all key statistics\n",
    "if 'ShortDurationVisual_grand_mean' in locals() and 'LongDurationVisual_grand_mean' in locals():\n",
    "    summary_report = {\n",
    "        \"metric\": [\n",
    "            \"Total participants\",\n",
    "            \"Total ShortDurationVisual trials\",\n",
    "            \"Total LongDurationVisual trials\",\n",
    "            \"Mean ShortDurationVisual baseline\",\n",
    "            \"Mean LongDurationVisual baseline\",\n",
    "            \"ShortDurationVisual peak amplitude\",\n",
    "            \"LongDurationVisual peak amplitude\",\n",
    "            \"ShortDurationVisual peak time (ms)\",\n",
    "            \"LongDurationVisual peak time (ms)\",\n",
    "            \"ShortDurationVisual AUC\",\n",
    "            \"LongDurationVisual AUC\",\n",
    "            \"ShortDurationVisual mean response\",\n",
    "            \"LongDurationVisual mean response\"\n",
    "        ],\n",
    "        \"value\": [\n",
    "            len(all_ShortDurationVisual_resampled),\n",
    "            len(all_participants_ShortDurationVisual_baselines),\n",
    "            len(all_participants_LongDurationVisual_baselines),\n",
    "            mean_ShortDurationVisual_baseline,\n",
    "            mean_LongDurationVisual_baseline,\n",
    "            ShortDurationVisual_peak_value,\n",
    "            LongDurationVisual_peak_value,\n",
    "            ShortDurationVisual_peak_time,\n",
    "            LongDurationVisual_peak_time,\n",
    "            ShortDurationVisual_auc,\n",
    "            LongDurationVisual_auc,\n",
    "            np.mean(ShortDurationVisual_grand_mean),\n",
    "            np.mean(LongDurationVisual_grand_mean)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    summary_report_df = pd.DataFrame(summary_report)\n",
    "    summary_report_df.to_csv(\"pupillometry_summary_report_v.csv\", index=False)\n",
    "    print(\"Saved comprehensive summary report to pupillometry_summary_report_v.csv\")\n",
    "\n",
    "# Check if we have both conditions to calculate difference measures\n",
    "if 'ShortDurationVisual_grand_mean' in locals() and 'LongDurationVisual_grand_mean' in locals():\n",
    "    # Calculate difference between conditions\n",
    "    condition_difference = LongDurationVisual_grand_mean - ShortDurationVisual_grand_mean\n",
    "    \n",
    "    # Export difference data\n",
    "    difference_data = {\n",
    "        \"time_ms\": time_axis,\n",
    "        \"LongDurationVisual_minus_ShortDurationVisual\": condition_difference\n",
    "    }\n",
    "    \n",
    "    difference_df = pd.DataFrame(difference_data)\n",
    "    difference_df.to_csv(\"condition_difference_v.csv\", index=False)\n",
    "    print(\"Saved condition difference data to condition_difference_v.csv\")\n",
    "    \n",
    "    # Plot difference between conditions\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    ax.plot(time_axis, condition_difference, 'g-', label=\"LongDurationVisual - ShortDurationVisual\")\n",
    "    ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Difference Between Conditions (LongDurationVisual - ShortDurationVisual)\")\n",
    "    ax.set_xlabel(\"Time (ms)\")\n",
    "    ax.set_ylabel(\"Difference in Pupil Diameter\")\n",
    "    plt.savefig(\"condition_difference_v.png\")\n",
    "\n",
    "print(\"All data processing and exports completed successfully!\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
